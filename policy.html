<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Power Moves | PlanetCo Insight</title>
    <link rel="stylesheet" href="style.css">
    <script src="script.js" defer></script>
</head>
<body>
    <header class="navbar">
        <a href="index.html" class="nav-logo">PlanetCo<span>.</span>Insight</a>
        <ul class="nav-links">
            <li><a href="index.html">Home</a></li>
            <li><a href="policy.html">AI Power Moves</a></li>
            <li><a href="culture.html">AI x Culture</a></li>
            <li><a href="research.html">Decoded Papers</a></li>
            <li><a href="tools.html">Tools</a></li>
            <li><a href="pulse.html">Pulse</a></li>
            <li><a href="about.html">About</a></li>
        </ul>
        <button class="mobile-menu-toggle">☰</button>
    </header>

    <main class="container section">
        <div class="section-title">
            <h1>AI Power Moves</h1>
            <p>Navigating the global chessboard of AI policy and geopolitics.</p>
        </div>

        <div class="policy-item card fade-in">
            <h3>The EU AI Act</h3>
            <p>The European Union's landmark legislation takes a risk-based approach, categorizing AI systems from "unacceptable risk" (banned) to "high," "limited," and "minimal" risk. It imposes strict transparency and quality requirements on high-risk systems, such as those used in critical infrastructure or law enforcement.</p>
            <div class="why-it-matters">
                <strong>Why it matters:</strong> The "Brussels Effect" is in play. Global companies wanting access to the EU market will likely adopt these standards worldwide, making it a de facto global benchmark for trustworthy AI.
            </div>
        </div>

        <div class="policy-item card fade-in" style="transition-delay: 0.2s;">
            <h3>USA's Executive Order on AI</h3>
            <p>The U.S. approach, outlined in a comprehensive Executive Order, focuses on balancing innovation with safety and security. It directs federal agencies to set new standards for AI safety, protect privacy, advance equity, and promote competition, without immediately enacting broad, EU-style legislation.</p>
            <div class="why-it-matters">
                <strong>Why it matters:</strong> This strategy prioritizes American leadership and rapid innovation, potentially creating a more flexible but fragmented regulatory environment compared to the EU. It heavily emphasizes the role of private sector standards bodies.
            </div>
        </div>

        <div class="policy-item card fade-in" style="transition-delay: 0.4s;">
            <h3>China's AI Governance</h3>
            <p>China is implementing a multi-faceted approach with specific regulations targeting areas like generative AI and algorithmic recommendations. The state plays a central role in directing AI development towards national strategic goals, while also enforcing strict content and data controls.</p>
            <div class="why-it-matters">
                <strong>Why it matters:</strong> China's model demonstrates a state-centric approach where AI development is tightly coupled with national security and social governance. This creates a powerful, but insular, AI ecosystem that competes directly with Western models on a global scale.
            </div>
        </div>
    </main>

    <footer class="footer">
        <ul class="social-links">
            <li><a href="#">X</a></li>
            <li><a href="#">LinkedIn</a></li>
            <li><a href="#">GitHub</a></li>
        </ul>
        <p>© 2024 PlanetCo Insight. The Future is a Collaborative Project.</p>
    </footer>
</body>
</html>